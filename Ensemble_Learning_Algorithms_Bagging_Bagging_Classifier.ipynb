{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging - Bagging Classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "UScGcOv1R2Ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando augoritimos bangging classifier no projeto"
      ],
      "metadata": {
        "id": "o_mOLwkOSJNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2bT6pVbRZar"
      },
      "outputs": [],
      "source": [
        "#  Importando as bibliotecas\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names=colunas)\n",
        "array = dados.values\n",
        "\n",
        "\n",
        "# separando o array em componetes  de input e outpul\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Definindo os valores para o numero de folds\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "\n",
        "# Definindo o número de trees\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Separando os dados em  Folds\n",
        "kfold = KFold(num_folds, True, random_state=seed)\n",
        "\n",
        "# criando o modelo\n",
        "modelo = BaggingClassifier(n_estimadores = num_trees, max_features = max_features)\n",
        "\n",
        "# cross validation\n",
        "resultado = cross_val_score(modelo, X, Y, cv = Kfolf)\n",
        "\n",
        "# print do resultado\n",
        "print(\"Acurácia: %.3f\" %(resultado.mean()* 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ExtraTree"
      ],
      "metadata": {
        "id": "GNwiehNM6tyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extremely Randomized Trees ou Árvores Extremamente Randomizadas.É um Algoritmo com um conjunto de árvores de decisão e está relacionado a outros conjuntos de algoritmos  de arvore decisão, como agregação de booststrap (bagging) e floresta aleatória.\n",
        "\n",
        "\n",
        "O algoritmo Extra Trees funciona criando um grande número de Árvore de decisão não ajustadas a partir do conjunto de dados de treinamento."
      ],
      "metadata": {
        "id": "Bhv1q_Js65HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Importando as bibliotecas\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names=colunas)\n",
        "array = dados.values\n",
        "\n",
        "\n",
        "# separando o array em componetes  de input e outpul\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Definindo os valores para o numero de folds\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "\n",
        "# Definindo o número de trees\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Separando os dados em  Folds\n",
        "kfold = KFold(num_folds, True, random_state=seed)\n",
        "\n",
        "# criando o modelo\n",
        "modelo = ExtraTreesClassifier(n_estimadores = num_trees, max_features = max_features)\n",
        "\n",
        "# cross validation\n",
        "resultado = cross_val_score(modelo, X, Y, cv = Kfolf)\n",
        "\n",
        "# print do resultado\n",
        "print(\"Acurácia: %.3f\" %(resultado.mean()* 100))\n"
      ],
      "metadata": {
        "id": "T_Lta9S4EuBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "xogdZRhaJcYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest e uma extensão do Baggig Decision Tree. Amostras do dataset de treino são usadas com reposição, mais as árvores são criadas de uma forma que reduz a correlação entre classificadores individuais (Random Forest e um conjunto de árvores de decisão)"
      ],
      "metadata": {
        "id": "D-W4osKhLCnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Importando as bibliotecas\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names=colunas)\n",
        "array = dados.values\n",
        "\n",
        "\n",
        "# separando o array em componetes  de input e outpul\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Definindo os valores para o numero de folds\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "\n",
        "# Definindo o número de trees\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Separando os dados em  Folds\n",
        "kfold = KFold(num_folds, True, random_state=seed)\n",
        "\n",
        "# criando o modelo\n",
        "modelo = RandomForestClassifier(n_estimadores = num_trees, max_features = max_features)\n",
        "\n",
        "# cross validation\n",
        "resultado = cross_val_score(modelo, X, Y, cv = Kfolf)\n",
        "\n",
        "# print do resultado\n",
        "print(\"Acurácia: %.3f\" %(resultado.mean()* 100))\n"
      ],
      "metadata": {
        "id": "317vCrG0Jjwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmos Boosting"
      ],
      "metadata": {
        "id": "3-xoFacRfbr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost**"
      ],
      "metadata": {
        "id": "JA8JpKCmfqsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O boosting adaptativo ou AdaBoost é um dos algoritmos de boosting mais simples , normalmente, as árvores de são usadas para modelagem. Vários modelos sequencias são criados, cada um corrigindo os erros do último modelo.AdaBoost atributo atribuido pesos ás observações que são prevista incorretamente e o modelo subsequente trabalha para prever eses valores corretamente."
      ],
      "metadata": {
        "id": "T0c3_ETwf1tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importando pacotes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# carregando os dados\n",
        "breast_cancer = load_breast_cancer()\n",
        "# separação das fetuares (variaveis) e do Target\n",
        "x = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
        "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
        "# transfomação da Label em numérico\n",
        "encoder = LabelEncoder()\n",
        "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
        "\n",
        "# Separação ou Amostragem\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state = 1)\n",
        "\n",
        "#criar e treinando a maquina preditiva\n",
        "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200)\n",
        "classifier.fit(train_x, train_y)\n",
        "\n",
        "#predição com dados de teste\n",
        "predictions = classifier.predict(test_x)\n",
        "\n",
        "# Avalição da MP\n",
        "confusion_matrix(test_y, predictions)\n",
        "\n",
        "accuracy = accuracy_score(test_y, predictions)\n",
        "print(\"AdaBoost Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "OIAIIkHmfyNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caso Pratico GBM"
      ],
      "metadata": {
        "id": "PA7Ifm2NtggR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importando os pacotes\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregando a base de dados\n",
        "bhp = datasets.load_boston()\n",
        "\n",
        "# Amostragem dos dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(bhp.data, bhp.target, random_state=7, test_size=0.1)\n",
        "\n",
        "# padronizando o dataset\n",
        "sc = StandardScaler()\n",
        "X_train_std = sc.fit_transform(x_train)\n",
        "x_test_std = sc.transform(x_test)\n",
        "\n",
        "# tunando ou calibrando os Hyperparameter for GradientBoostingRegressor\n",
        "gbr_params = {'n_estimadors': 1000,\n",
        "              'max_depth': 3,\n",
        "              'min_samples_split':5,\n",
        "              'learning_rate': 0.01,\n",
        "              }\n",
        "\n",
        "\n",
        "# criando a Maquina preditiva\n",
        "gbr = GradientBoostingRegressor(**gbr_params)\n",
        "\n",
        "\n",
        "# treinando a MP\n",
        "gbr.fit(x_train_std, y_train)\n",
        "\n",
        "# Avaliando a MP com a Métrica R2 ( coefficient of determination R^2)\n",
        "\n",
        "print(\"Model Accuracy:  %.3f\" % gbr.score(X_test_std, y_test))\n",
        "\n",
        "# Avaliando as metrica MSE (create the mean squared error)\n",
        "mse = mean_squared_error(y_test, gbr.predict(X_test_std))\n",
        "print(\"the mean squared error(MSE) on test set: {:,4f}\",format(mse))"
      ],
      "metadata": {
        "id": "WuakOLyrucGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliando a importância das variaveis com GBM"
      ],
      "metadata": {
        "id": "Httg6SD2Js0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import permutation_importance\n",
        "\n",
        "\n",
        "feature_importances = gbr.feature_importances_\n",
        "\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, np.array(bhp.feature_names)[sorted_idx])\n",
        "plt.title('Feature Importance (GMB)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pLQOPL7LKqPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB"
      ],
      "metadata": {
        "id": "ci9A35yyR-Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Importando as bibliotecas\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names=colunas)\n",
        "array = dados.values\n",
        "\n",
        "\n",
        "# separando o array em componetes  de input e outpul\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Definindo o tamanho dos dados da treino e teste\n",
        "teste_size = 0.1\n",
        "seed = 7\n",
        "\n",
        "# criando o dataset de treino e teste\n",
        "X_treino, X_teste, Y_treino, Y_teste = train_test_split(x, y, test_size = teste_size, random_state = seed)\n",
        "\n",
        "# criando o modelo\n",
        "modelo = XGBClassifier()\n",
        "\n",
        "# treinando o modelo\n",
        "modelo.fit(X_treino, Y_treino)\n",
        "\n",
        "\n",
        "# fazendo previsoes\n",
        "Y_pred = modelo.predict(X_teste)\n",
        "previsoes = [round(value) for value in Y_pred]\n",
        "\n",
        "# print do resultado\n",
        "acuracia = accuracy_score(Y_teste, previsoes)\n",
        "print(\"Acurácia: %.3f\" %(acuracia.mean()* 100))\n"
      ],
      "metadata": {
        "id": "7ld68QFkSD1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}